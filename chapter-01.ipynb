{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1fb655a-165f-4c0b-a6ef-c18efbdd982b",
   "metadata": {},
   "source": [
    "# Learning from Unlabeled Data: Rise of Semi-Supervised and Self-Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ad4fc6-8791-4ed2-84b1-a0dafd7d4fb5",
   "metadata": {},
   "source": [
    "## Technical requirements\n",
    "\n",
    "We will use the following as technical requirements to run the code in this chapter:\n",
    "- Python 3\n",
    "- pip\n",
    "- Tensorflow (with CUDA if you want to train models on GPUs)\n",
    "    - Keras is installed as a dependency to this\n",
    "- scikit-learn Python library\n",
    "    - Numpy is installed as a dependency to this\n",
    "- Jupyter notebook if running the code directly from Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9baf5c-3c15-4027-845f-b0e48558cc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3 -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50eca89-3c16-4e9a-84ef-9c03987f421c",
   "metadata": {},
   "source": [
    "### For M1+ Macbook (64-bit ARM Based processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1a3d11-840b-4e9d-b4f4-d65251539321",
   "metadata": {},
   "outputs": [],
   "source": [
    "! arch -arm64 pip3 install --upgrade pip\n",
    "! arch -arm64 pip3 install tensorflow\n",
    "! arch -arm64 pip3 install -U scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b53183a-e958-45e1-b8b5-7441ce2fe33a",
   "metadata": {},
   "source": [
    "### For Other Computer Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcb74ba-2928-4754-937d-c82123556992",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install --upgrade pip\n",
    "! pip3 install tensorflow\n",
    "! pip3 install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d2fd6e-8275-4118-9be7-998d878922b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d96b57-272e-474a-a30b-bf673d970490",
   "metadata": {},
   "source": [
    "## 1. Introduction to Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb65719-981b-4b73-b3eb-d4a8b82a98de",
   "metadata": {},
   "source": [
    "### 1.1 Building a Machine Learning Model\n",
    "\n",
    "We usually divide the given data into 2 subsets - one for training and other for testing. Below we will use __[CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html)__ dataset to build a classifier model and a clustering model.\n",
    "\n",
    "More information about the dataset could be found at __[Learning Multiple Layers of Features from Tiny Images](https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf)__, Alex Krizhevsky, 2009.\n",
    "\n",
    "You can see we first load the train and test images and labels and then normalize each image to be in range [-1, 1] before it could be fed into our ML model for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4e6347-42cc-4eff-a0cd-5df62477a190",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "train_images = train_images / 127.5 - 1\n",
    "test_images = test_images / 127.5 - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96afcd93-67bf-4cf2-b519-3dc44686cdc1",
   "metadata": {},
   "source": [
    "Next, we need to decide on the right learning method and algorithm that would solve the problem at hand. If the problem is to predict classes for each test image, we would train the model using labels of each image through a convolutional neural network as described below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010eede7-06cc-481f-9aab-13a7ae6e773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1d4cf3-6771-4bec-85d0-adaec401ebbb",
   "metadata": {},
   "source": [
    "Next, we would select an appropriate loss function and optimization technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0434920b-cdc4-4e75-a01b-180eabf1a34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2309806-77eb-45bb-acb9-a940af16f96d",
   "metadata": {},
   "source": [
    "Finally, we train the model, validate and test it using the right evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4312414e-77cd-4557-9afc-df470246958e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5bd415-3f6d-4df1-89e4-4a4e5894dc4b",
   "metadata": {},
   "source": [
    "We'll get the output as follows for each epoch and final test accuracy.\n",
    "\n",
    "But if the problem is to create clusters of images that represent the same group of entities, we would not use any labels for that purpose. So we collate training and test images and flatten them so that we can use a K-means clustering algortihm to get image clusters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6e3c7f-f46c-4628-953e-0c95786534b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.concatenate((train_images, test_images))\n",
    "images_flattened = images.reshape(images.shape[0], -1)\n",
    "\n",
    "kmeans = KMeans(n_clusters=10, random_state=42)\n",
    "cluster_assignments = kmeans.fit_predict(images_flattened)\n",
    "\n",
    "print(cluster_assignments[:100])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book_venv",
   "language": "python",
   "name": "book_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
